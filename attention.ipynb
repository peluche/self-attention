{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1767YGfJBUJ"
      },
      "source": [
        "# self-attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6uEL9POJdJg"
      },
      "source": [
        "## setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "eZ2JLTWoI2Xc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import copy\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device = \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "R5UzPzqsJ1DM"
      },
      "outputs": [],
      "source": [
        "EMBED_SIZE = 8\n",
        "VOCAB_SIZE = 11\n",
        "HIDDEN_SIZE = 32\n",
        "CONTEXT_SIZE = 10\n",
        "MAGIC_TOKEN = VOCAB_SIZE-1\n",
        "MAX_ITERS = 10000\n",
        "LEARNING_RATE = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "sLH6wwNFmoPp"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "Y = []\n",
        "\n",
        "for i in range(1000):\n",
        "  magic_token_idx = random.randint(1, CONTEXT_SIZE/2 -1)\n",
        "  x = [random.randint(1,VOCAB_SIZE-2) for _ in range(magic_token_idx)] + [MAGIC_TOKEN] + [0 for _ in range(CONTEXT_SIZE-magic_token_idx -1)]\n",
        "  y = x[:magic_token_idx+1] + x[:magic_token_idx] + [0 for _ in range(CONTEXT_SIZE - 2*magic_token_idx -1)]\n",
        "  X.append(x)\n",
        "  Y.append(y)\n",
        "\n",
        "X = torch.tensor(X).to(device)\n",
        "Y= torch.tensor(Y).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwuS4B5TJfVW"
      },
      "source": [
        "## code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "2svm5EyvNtMa"
      },
      "outputs": [],
      "source": [
        "def get_training():\n",
        "  X = torch.tensor([[0, 1, 2, 3],\n",
        "                    [3, 2, 1, 0]])\n",
        "\n",
        "  X = torch.randint(0, VOCAB_SIZE-2, (1000, CONTEXT_SIZE))\n",
        "\n",
        "  Y = torch.ones_like(X) # TODO\n",
        "  return X.to(device), Y.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "NyzZx3uXJam-"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.w_key = torch.nn.Linear(EMBED_SIZE, EMBED_SIZE, bias=False)\n",
        "    self.w_query = torch.nn.Linear(EMBED_SIZE, EMBED_SIZE, bias=False)\n",
        "    self.w_value = torch.nn.Linear(EMBED_SIZE, EMBED_SIZE, bias=False)\n",
        "    self.ln = nn.LayerNorm(EMBED_SIZE)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # generate K,Q,V\n",
        "    key = self.w_key(x)\n",
        "    query = self.w_query(x)\n",
        "    value = self.w_value(x)\n",
        "    # do the attention\n",
        "    correlation = query @ key.transpose(-2, -1)\n",
        "    correlation = correlation / math.sqrt(key.shape[-1])\n",
        "    new_embedding = correlation.softmax(-1) @ value\n",
        "    # layer norm\n",
        "    new_embedding = self.ln(new_embedding)\n",
        "    return new_embedding\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.token_embedding = nn.Embedding(VOCAB_SIZE, EMBED_SIZE)\n",
        "    self.positional_embedding = nn.Embedding(CONTEXT_SIZE, EMBED_SIZE)\n",
        "    self.attention = Attention()\n",
        "    self.ff = nn.Sequential(\n",
        "      nn.Linear(EMBED_SIZE, HIDDEN_SIZE),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(HIDDEN_SIZE, EMBED_SIZE),\n",
        "      nn.LayerNorm(EMBED_SIZE),\n",
        "    )\n",
        "    self.head = nn.Linear(EMBED_SIZE, VOCAB_SIZE)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x: (batch_size, context_size)\n",
        "    x = self.token_embedding(x)  # (batch_size, context_size, embedding_size)\n",
        "    # positional encoding\n",
        "    x = x + self.positional_embedding(torch.arange(0, x.shape[1]).to(device))\n",
        "    # attention\n",
        "    x = x + self.attention(x)\n",
        "    # feed forward\n",
        "    x = x + self.ff(x)\n",
        "    # head\n",
        "    x = self.head(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "qnggoXHwK7zo"
      },
      "outputs": [],
      "source": [
        "model = Net().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "gDVu722fp_PW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    0 0.05184357240796089\n",
            "  500 0.048021651804447174\n",
            " 1000 0.046429093927145004\n",
            " 1500 0.044264405965805054\n",
            " 2000 0.043660808354616165\n",
            " 2500 0.036411285400390625\n",
            " 3000 0.03408998250961304\n",
            " 3500 0.030521320179104805\n",
            " 4000 0.027178823947906494\n",
            " 4500 0.024127095937728882\n",
            " 5000 0.020261602476239204\n",
            " 5500 0.01299357134848833\n",
            " 6000 0.010142686776816845\n",
            " 6500 0.008977246470749378\n",
            " 7000 0.0033558951690793037\n",
            " 7500 0.008173685520887375\n",
            " 8000 0.0026782879140228033\n",
            " 8500 0.001965648028999567\n",
            " 9000 0.0015759249217808247\n",
            " 9500 0.0011593375820666552\n"
          ]
        }
      ],
      "source": [
        "### train\n",
        "opt = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "for epoch in range(MAX_ITERS):\n",
        "  out = model(X)\n",
        "  loss = F.cross_entropy(out.view(-1, out.shape[-1]), Y.view(-1))\n",
        "  opt.zero_grad()\n",
        "  loss.backward()\n",
        "  opt.step()\n",
        "  if epoch % 500 == 0:\n",
        "    print(f'{epoch:5} {loss.item()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xhSeSabbVMF",
        "outputId": "6838c255-35b8-4f0e-81da-8714c9e24216"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy: 1.0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[ 1, 10,  1,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 6,  1,  7,  2, 10,  6,  1,  7,  2,  0],\n",
              "        [ 4,  6, 10,  4,  6,  0,  0,  0,  0,  0],\n",
              "        [ 9,  1,  4,  5, 10,  9,  1,  4,  5,  0],\n",
              "        [ 5,  1,  4,  5, 10,  5,  1,  4,  5,  0],\n",
              "        [ 8,  7,  1, 10,  8,  7,  1,  0,  0,  0],\n",
              "        [ 4,  7, 10,  4,  7,  0,  0,  0,  0,  0],\n",
              "        [ 6, 10,  6,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 5,  9, 10,  5,  9,  0,  0,  0,  0,  0],\n",
              "        [ 5,  8,  8,  9, 10,  5,  8,  8,  9,  0],\n",
              "        [ 7, 10,  7,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 7,  3,  3,  1, 10,  7,  3,  3,  1,  0],\n",
              "        [ 9, 10,  9,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 4,  8, 10,  4,  8,  0,  0,  0,  0,  0],\n",
              "        [ 8, 10,  8,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 4,  2,  6, 10,  4,  2,  6,  0,  0,  0],\n",
              "        [ 6,  5,  1, 10,  6,  5,  1,  0,  0,  0],\n",
              "        [ 8,  1,  5, 10,  8,  1,  5,  0,  0,  0],\n",
              "        [ 7,  3,  8, 10,  7,  3,  8,  0,  0,  0],\n",
              "        [ 1,  6,  5,  8, 10,  1,  6,  5,  8,  0]])"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res = model(X).argmax(-1)\n",
        "correct = ((res == Y).float().sum(-1) == CONTEXT_SIZE).float().sum()\n",
        "print(f'accuracy: {correct / len(X)}')\n",
        "res[:20]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "venv_hf_nlp",
      "language": "python",
      "name": "venv_hf_nlp"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
