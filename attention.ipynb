{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1767YGfJBUJ"
      },
      "source": [
        "# self-attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6uEL9POJdJg"
      },
      "source": [
        "## setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "eZ2JLTWoI2Xc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import copy\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device = \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "R5UzPzqsJ1DM"
      },
      "outputs": [],
      "source": [
        "EMBED_SIZE = 8\n",
        "VOCAB_SIZE = 11\n",
        "HIDDEN_SIZE = 32\n",
        "CONTEXT_SIZE = 10\n",
        "MAGIC_TOKEN = VOCAB_SIZE-1\n",
        "MAX_ITERS = 10000\n",
        "LEARNING_RATE = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "sLH6wwNFmoPp"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "Y = []\n",
        "\n",
        "for i in range(1000):\n",
        "  magic_token_idx = random.randint(1, CONTEXT_SIZE/2 -1)\n",
        "  x = [random.randint(1,VOCAB_SIZE-2) for _ in range(magic_token_idx)] + [MAGIC_TOKEN] + [0 for _ in range(CONTEXT_SIZE-magic_token_idx -1)]\n",
        "  y = x[:magic_token_idx+1] + x[:magic_token_idx] + [0 for _ in range(CONTEXT_SIZE - 2*magic_token_idx -1)]\n",
        "  X.append(x)\n",
        "  Y.append(y)\n",
        "\n",
        "X = torch.tensor(X).to(device)\n",
        "Y= torch.tensor(Y).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwuS4B5TJfVW"
      },
      "source": [
        "## code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "2svm5EyvNtMa"
      },
      "outputs": [],
      "source": [
        "def get_training():\n",
        "  X = torch.tensor([[0, 1, 2, 3],\n",
        "                    [3, 2, 1, 0]])\n",
        "\n",
        "  X = torch.randint(0, VOCAB_SIZE-2, (1000, CONTEXT_SIZE))\n",
        "\n",
        "  Y = torch.ones_like(X) # TODO\n",
        "  return X.to(device), Y.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "NyzZx3uXJam-"
      },
      "outputs": [],
      "source": [
        "# class Attention(nn.Module):\n",
        "#   def __init__(self):\n",
        "#     super().__init__()\n",
        "#     self.w_key = torch.nn.Linear(EMBED_SIZE, EMBED_SIZE, bias=False)\n",
        "#     self.w_query = torch.nn.Linear(EMBED_SIZE, EMBED_SIZE, bias=False)\n",
        "#     self.w_value = torch.nn.Linear(EMBED_SIZE, EMBED_SIZE, bias=False)\n",
        "\n",
        "#   def forward(self, x):\n",
        "#     # generate K,Q,V\n",
        "#     key = self.w_key(x) #(batch_size, context_size, embedding_size) @ (embedding_size, embedding_size) ---> (batch_size, context_size, embedding_size)\n",
        "#     query = self.w_query(x)\n",
        "#     value = self.w_value(x)\n",
        "#     # do the attention\n",
        "#     correlation = query @ key.transpose(-2, -1)\n",
        "#     correlation = correlation / math.sqrt(key.shape[-1])\n",
        "#     new_embedding = correlation.softmax(-1) @ value\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.token_embedding = torch.nn.Embedding(VOCAB_SIZE, EMBED_SIZE)\n",
        "    self.positional_embedding = torch.nn.Embedding(CONTEXT_SIZE, EMBED_SIZE)\n",
        "\n",
        "    self.w_key = torch.nn.Linear(EMBED_SIZE, EMBED_SIZE, bias=False)\n",
        "    self.w_query = torch.nn.Linear(EMBED_SIZE, EMBED_SIZE, bias=False)\n",
        "    self.w_value = torch.nn.Linear(EMBED_SIZE, EMBED_SIZE, bias=False)\n",
        "\n",
        "    self.emb_ln = nn.LayerNorm(EMBED_SIZE)\n",
        "\n",
        "    self.ff = nn.Sequential(\n",
        "      nn.Linear(EMBED_SIZE, HIDDEN_SIZE),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(HIDDEN_SIZE, EMBED_SIZE),\n",
        "      nn.LayerNorm(EMBED_SIZE),\n",
        "    )\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(EMBED_SIZE, VOCAB_SIZE),\n",
        "    )\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x: (batch_size, context_size)\n",
        "    x = self.token_embedding(x)  # (batch_size, context_size, embedding_size)\n",
        "    # positional embedding\n",
        "    x = x + self.positional_embedding(torch.arange(0, x.shape[1]).to(device))  # (batch_size, context_size, embedding_size)\n",
        "\n",
        "    # generate K,Q,V\n",
        "    key = self.w_key(x) #(batch_size, context_size, embedding_size) @ (embedding_size, embedding_size) ---> (batch_size, context_size, embedding_size)\n",
        "    query = self.w_query(x)\n",
        "    value = self.w_value(x)\n",
        "    # do the attention\n",
        "    correlation = query @ key.transpose(-2, -1)\n",
        "    correlation = correlation / math.sqrt(key.shape[-1])\n",
        "    new_embedding = correlation.softmax(-1) @ value\n",
        "\n",
        "    x = x + self.emb_ln(new_embedding)\n",
        "\n",
        "    # layernorm + MLP\n",
        "    fed = self.ff(x)\n",
        "    x = x + fed\n",
        "    x = self.layers(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "k.shape=torch.Size([2, 4, 8]) k.transpose(-2, -1).shape=torch.Size([2, 8, 4]) (q @ k.transpose(-2, -1)).shape=torch.Size([2, 4, 4])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(tensor([[[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],\n",
              "          [ 8.,  9., 10., 11., 12., 13., 14., 15.],\n",
              "          [16., 17., 18., 19., 20., 21., 22., 23.],\n",
              "          [24., 25., 26., 27., 28., 29., 30., 31.]],\n",
              " \n",
              "         [[32., 33., 34., 35., 36., 37., 38., 39.],\n",
              "          [40., 41., 42., 43., 44., 45., 46., 47.],\n",
              "          [48., 49., 50., 51., 52., 53., 54., 55.],\n",
              "          [56., 57., 58., 59., 60., 61., 62., 63.]]]),\n",
              " tensor([[[ 0.,  8., 16., 24.],\n",
              "          [ 1.,  9., 17., 25.],\n",
              "          [ 2., 10., 18., 26.],\n",
              "          [ 3., 11., 19., 27.],\n",
              "          [ 4., 12., 20., 28.],\n",
              "          [ 5., 13., 21., 29.],\n",
              "          [ 6., 14., 22., 30.],\n",
              "          [ 7., 15., 23., 31.]],\n",
              " \n",
              "         [[32., 40., 48., 56.],\n",
              "          [33., 41., 49., 57.],\n",
              "          [34., 42., 50., 58.],\n",
              "          [35., 43., 51., 59.],\n",
              "          [36., 44., 52., 60.],\n",
              "          [37., 45., 53., 61.],\n",
              "          [38., 46., 54., 62.],\n",
              "          [39., 47., 55., 63.]]]),\n",
              " tensor([[[ 28.,  92., 156., 220.],\n",
              "          [ 28.,  92., 156., 220.],\n",
              "          [ 28.,  92., 156., 220.],\n",
              "          [ 28.,  92., 156., 220.]],\n",
              " \n",
              "         [[284., 348., 412., 476.],\n",
              "          [284., 348., 412., 476.],\n",
              "          [284., 348., 412., 476.],\n",
              "          [284., 348., 412., 476.]]]))"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "k = torch.arange(2*4*8).view([2, 4, 8]).float()\n",
        "# k = torch.ones([2, 4, 8])\n",
        "q = torch.ones([2, 4, 8])\n",
        "\n",
        "# Why does this match ?!\n",
        "# ----------------------\n",
        "q @ k.transpose(-2, -1)\n",
        "print(f'{k.shape=} {k.transpose(-2, -1).shape=} {(q @ k.transpose(-2, -1)).shape=}')\n",
        "\n",
        "k, k.transpose(-2, -1), q @ k.transpose(-2, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "qnggoXHwK7zo"
      },
      "outputs": [],
      "source": [
        "model = Net().to(device)\n",
        "# X, Y = get_training()\n",
        "# model(X).argmax(dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "gDVu722fp_PW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    0 2.904038190841675\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  500 0.44902303814888\n",
            " 1000 0.17360185086727142\n",
            " 1500 0.09929771721363068\n",
            " 2000 0.06542648375034332\n",
            " 2500 0.045226242393255234\n",
            " 3000 0.03154982998967171\n",
            " 3500 0.023086871951818466\n",
            " 4000 0.016843700781464577\n",
            " 4500 0.014822080731391907\n",
            " 5000 0.009837410412728786\n",
            " 5500 0.007400656118988991\n",
            " 6000 0.007868007756769657\n",
            " 6500 0.005057420581579208\n",
            " 7000 0.0038744830526411533\n",
            " 7500 0.0029830269049853086\n",
            " 8000 0.0022892651613801718\n",
            " 8500 0.0037419490981847048\n",
            " 9000 0.0024802726693451405\n",
            " 9500 0.002011876553297043\n"
          ]
        }
      ],
      "source": [
        "### train\n",
        "opt = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "for epoch in range(MAX_ITERS):\n",
        "  out = model(X)\n",
        "\n",
        "  # Why are these 2 not equivalent?\n",
        "  # -------------------------------\n",
        "  # loss = F.cross_entropy(out, F.one_hot(Y, VOCAB_SIZE).float())\n",
        "  loss = F.cross_entropy(out.view(-1, out.shape[-1]), Y.view(-1))\n",
        "\n",
        "  opt.zero_grad()\n",
        "  loss.backward()\n",
        "  opt.step()\n",
        "  if epoch % 500 == 0:\n",
        "    print(f'{epoch:5} {loss.item()}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xhSeSabbVMF",
        "outputId": "6838c255-35b8-4f0e-81da-8714c9e24216"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[3, 6, 5, 1, 10, 3, 6, 5, 1, 0],\n",
              " [9, 7, 8, 9, 10, 9, 7, 8, 9, 0],\n",
              " [7, 2, 4, 10, 7, 2, 4, 0, 0, 0],\n",
              " [3, 1, 10, 3, 1, 0, 0, 0, 0, 0],\n",
              " [5, 2, 10, 5, 2, 0, 0, 0, 0, 0],\n",
              " [9, 1, 2, 4, 10, 9, 1, 2, 4, 0],\n",
              " [8, 4, 10, 8, 4, 0, 0, 0, 0, 0],\n",
              " [9, 6, 10, 9, 6, 0, 0, 0, 0, 0],\n",
              " [8, 1, 6, 2, 10, 8, 1, 6, 2, 0],\n",
              " [7, 8, 10, 7, 8, 0, 0, 0, 0, 0]]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model(X).argmax(-1).tolist()[:10]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "venv_hf_nlp",
      "language": "python",
      "name": "venv_hf_nlp"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
