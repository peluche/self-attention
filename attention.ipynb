{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1767YGfJBUJ"
      },
      "source": [
        "# self-attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6uEL9POJdJg"
      },
      "source": [
        "## setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {
        "id": "eZ2JLTWoI2Xc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import copy\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {
        "id": "R5UzPzqsJ1DM"
      },
      "outputs": [],
      "source": [
        "EMBED_SIZE = 8\n",
        "VOCAB_SIZE = 11\n",
        "HIDDEN_SIZE = 32\n",
        "CONTEXT_SIZE = 10\n",
        "MAGIC_TOKEN = VOCAB_SIZE-1\n",
        "EPOCHS = 10000\n",
        "LEARNING_RATE = 3e-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {
        "id": "sLH6wwNFmoPp"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "Y = []\n",
        "\n",
        "for i in range(1000):\n",
        "  magic_token_idx = random.randint(1, CONTEXT_SIZE/2 -1)\n",
        "  x = [random.randint(1,VOCAB_SIZE-2) for _ in range(magic_token_idx)] + [MAGIC_TOKEN] + [0 for _ in range(CONTEXT_SIZE - magic_token_idx - 1)]\n",
        "  y = x[:magic_token_idx+1] + x[:magic_token_idx] + [0 for _ in range(CONTEXT_SIZE - 2 * magic_token_idx - 1)]\n",
        "  X.append(x)\n",
        "  Y.append(y)\n",
        "\n",
        "X = torch.tensor(X).to(device)\n",
        "Y= torch.tensor(Y).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwuS4B5TJfVW"
      },
      "source": [
        "## code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 288,
      "metadata": {
        "id": "2svm5EyvNtMa"
      },
      "outputs": [],
      "source": [
        "def get_training():\n",
        "  X = torch.tensor([[0, 1, 2, 3],\n",
        "                    [3, 2, 1, 0]])\n",
        "\n",
        "  X = torch.randint(0, VOCAB_SIZE-2, (1000, CONTEXT_SIZE))\n",
        "\n",
        "  Y = torch.ones_like(X) # TODO\n",
        "  return X.to(device), Y.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 289,
      "metadata": {
        "id": "NyzZx3uXJam-"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.w_key = torch.nn.Linear(EMBED_SIZE, EMBED_SIZE, bias=False)\n",
        "    self.w_query = torch.nn.Linear(EMBED_SIZE, EMBED_SIZE, bias=False)\n",
        "    self.w_value = torch.nn.Linear(EMBED_SIZE, EMBED_SIZE, bias=False)\n",
        "    self.ln = nn.LayerNorm(EMBED_SIZE)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # generate K,Q,V\n",
        "    key = self.w_key(x)\n",
        "    query = self.w_query(x)\n",
        "    value = self.w_value(x)\n",
        "    # pre-layernorm\n",
        "    # x = self.ln(x)\n",
        "    # do the attention\n",
        "    correlation = query @ key.transpose(-2, -1)\n",
        "    correlation = correlation / math.sqrt(key.shape[-1])\n",
        "    new_embedding = correlation.softmax(-1) @ value\n",
        "    # post-layernorm\n",
        "    new_embedding = self.ln(new_embedding)\n",
        "    return new_embedding\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.token_embedding = nn.Embedding(VOCAB_SIZE, EMBED_SIZE)\n",
        "    self.positional_embedding = nn.Embedding(CONTEXT_SIZE, EMBED_SIZE)\n",
        "    self.attention = Attention()\n",
        "    self.ff = nn.Sequential(\n",
        "      nn.Linear(EMBED_SIZE, HIDDEN_SIZE),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(HIDDEN_SIZE, EMBED_SIZE),\n",
        "      nn.LayerNorm(EMBED_SIZE),\n",
        "    )\n",
        "    self.head = nn.Linear(EMBED_SIZE, VOCAB_SIZE)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # (batch_size, context_size)\n",
        "    x = self.token_embedding(x)  # (batch_size, context_size, embedding_size)\n",
        "    # positional encoding\n",
        "    x = x + self.positional_embedding(torch.arange(0, x.shape[1]).to(device))\n",
        "    # attention\n",
        "    x = x + self.attention(x)\n",
        "    # feed forward\n",
        "    x = x + self.ff(x)\n",
        "    # head\n",
        "    x = self.head(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 290,
      "metadata": {
        "id": "qnggoXHwK7zo"
      },
      "outputs": [],
      "source": [
        "model = Net().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 291,
      "metadata": {
        "id": "gDVu722fp_PW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    0 2.5265917778015137\n",
            "  500 0.9128351807594299\n",
            " 1000 0.4808105528354645\n",
            " 1500 0.29808908700942993\n",
            " 2000 0.21623677015304565\n",
            " 2500 0.16821356117725372\n",
            " 3000 0.13157570362091064\n",
            " 3500 0.10579367727041245\n",
            " 4000 0.08433056622743607\n",
            " 4500 0.06761296838521957\n",
            " 5000 0.053498268127441406\n",
            " 5500 0.04267818480730057\n",
            " 6000 0.03486316278576851\n",
            " 6500 0.028382284566760063\n",
            " 7000 0.02384473755955696\n",
            " 7500 0.020177608355879784\n",
            " 8000 0.017205029726028442\n",
            " 8500 0.015238409861922264\n",
            " 9000 0.012392907403409481\n",
            " 9500 0.011136529967188835\n"
          ]
        }
      ],
      "source": [
        "def train(model, epochs=EPOCHS, lr=LEARNING_RATE):\n",
        "  opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    out = model(X)\n",
        "    loss = F.cross_entropy(out.view(-1, out.shape[-1]), Y.view(-1))\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    if epoch % 500 == 0:\n",
        "      print(f'{epoch:5} {loss.item()}')\n",
        "\n",
        "train(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xhSeSabbVMF",
        "outputId": "6838c255-35b8-4f0e-81da-8714c9e24216"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy: 0.9850000739097595\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[ 9,  1,  1,  7, 10,  9,  1,  1,  7,  0],\n",
              "        [ 8,  4,  5,  3, 10,  8,  4,  5,  3,  0],\n",
              "        [ 6, 10,  6,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 2,  9, 10,  2,  9,  0,  0,  0,  0,  0],\n",
              "        [ 9,  9, 10,  9,  9,  0,  0,  0,  0,  0],\n",
              "        [ 3,  4, 10,  3,  4,  0,  0,  0,  0,  0],\n",
              "        [ 6,  1,  9,  9, 10,  6,  1,  9,  9,  0],\n",
              "        [ 9,  8,  2, 10,  9,  8,  2,  0,  0,  0],\n",
              "        [ 9,  6,  8, 10,  9,  6,  8,  0,  0,  0],\n",
              "        [ 6,  9, 10,  6,  9,  0,  0,  0,  0,  0],\n",
              "        [ 6,  4,  2, 10,  4,  4,  2,  0,  0,  0],\n",
              "        [ 1, 10,  1,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 7,  1,  7, 10,  7,  1,  7,  0,  0,  0],\n",
              "        [ 2,  9, 10,  2,  9,  0,  0,  0,  0,  0],\n",
              "        [ 8,  4,  2,  3, 10,  8,  4,  2,  3,  0],\n",
              "        [ 1,  2, 10,  1,  2,  0,  0,  0,  0,  0],\n",
              "        [ 7,  5,  5, 10,  7,  5,  5,  0,  0,  0],\n",
              "        [ 2,  7,  9, 10,  2,  7,  9,  0,  0,  0],\n",
              "        [ 6,  4, 10,  6,  4,  0,  0,  0,  0,  0],\n",
              "        [ 2,  4,  7, 10,  2,  4,  7,  0,  0,  0]], device='cuda:0')"
            ]
          },
          "execution_count": 292,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res = model(X).argmax(-1)\n",
        "correct = ((res == Y).float().sum(-1) == CONTEXT_SIZE).float().sum()\n",
        "print(f'accuracy: {correct / len(X)}')\n",
        "res[:20]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "venv_hf_nlp",
      "language": "python",
      "name": "venv_hf_nlp"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
